models:
  gpt-3.5-turbo:
    provider: openai
    model_name: gpt-3.5-turbo
    context_length: 4096
    metadata:
      max_tokens: 2048
      temperature: 0.7
  
  deepseek-chat:
    provider: deepseek
    model_name: deepseek-chat
    context_length: 4096
    metadata:
      max_tokens: 2048
      temperature: 0.7
